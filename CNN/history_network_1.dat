size of categorical data ------->(150000, 396)
size of numerical data   ------->(150000, 1)
***** Using 120000 samples for training and 30000 for validation *****
Model: "sisben_network_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 396)]        0                                            
__________________________________________________________________________________________________
layer1 (Dense)                  (None, 256)          101632      input_1[0][0]                    
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
layer2 (Dense)                  (None, 512)          131584      layer1[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 128)          256         input_2[0][0]                    
__________________________________________________________________________________________________
layer3 (Dense)                  (None, 256)          131328      layer2[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 16)           2064        dense[0][0]                      
__________________________________________________________________________________________________
predictions (Dense)             (None, 4)            1028        layer3[0][0]                     
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 2)            34          dense_1[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 6)            0           predictions[0][0]                
                                                                 dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 2)            14          concatenate[0][0]                
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            12          dense_3[0][0]                    
==================================================================================================
Total params: 367,952
Trainable params: 367,952
Non-trainable params: 0
__________________________________________________________________________________________________
None
# Fit model on training data

Train on 120000 samples, validate on 30000 samples
Epoch 1/100
120000/120000 - 40s - loss: 1.8357 - accuracy: 0.3819 - val_loss: 1.2407 - val_accuracy: 0.4021
Epoch 2/100
120000/120000 - 31s - loss: 1.2251 - accuracy: 0.4192 - val_loss: 1.1989 - val_accuracy: 0.4201
Epoch 3/100
120000/120000 - 32s - loss: 1.1909 - accuracy: 0.4387 - val_loss: 1.1643 - val_accuracy: 0.4591
Epoch 4/100
120000/120000 - 34s - loss: 1.1621 - accuracy: 0.4925 - val_loss: 1.1376 - val_accuracy: 0.4973
Epoch 5/100
120000/120000 - 33s - loss: 1.1395 - accuracy: 0.4997 - val_loss: 1.1139 - val_accuracy: 0.5107
Epoch 6/100
120000/120000 - 35s - loss: 1.1238 - accuracy: 0.5037 - val_loss: 1.1044 - val_accuracy: 0.5368
Epoch 7/100
120000/120000 - 32s - loss: 1.1124 - accuracy: 0.5271 - val_loss: 1.0926 - val_accuracy: 0.5393
Epoch 8/100
120000/120000 - 32s - loss: 1.1018 - accuracy: 0.5297 - val_loss: 1.1399 - val_accuracy: 0.5022
Epoch 9/100
120000/120000 - 32s - loss: 1.0967 - accuracy: 0.5305 - val_loss: 1.1484 - val_accuracy: 0.4941
Epoch 10/100
120000/120000 - 32s - loss: 1.0915 - accuracy: 0.5317 - val_loss: 1.1343 - val_accuracy: 0.5081
Epoch 11/100
120000/120000 - 33s - loss: 1.0859 - accuracy: 0.5334 - val_loss: 1.0784 - val_accuracy: 0.5405
Epoch 12/100
120000/120000 - 34s - loss: 1.0792 - accuracy: 0.5356 - val_loss: 1.0910 - val_accuracy: 0.5300
Epoch 13/100
120000/120000 - 30s - loss: 1.0762 - accuracy: 0.5368 - val_loss: 1.0630 - val_accuracy: 0.5420
Epoch 14/100
120000/120000 - 30s - loss: 1.0721 - accuracy: 0.5388 - val_loss: 1.1035 - val_accuracy: 0.5214
Epoch 15/100
120000/120000 - 31s - loss: 1.0700 - accuracy: 0.5379 - val_loss: 1.0768 - val_accuracy: 0.5407
Epoch 16/100
120000/120000 - 31s - loss: 1.0676 - accuracy: 0.5397 - val_loss: 1.0594 - val_accuracy: 0.5418
Epoch 17/100
120000/120000 - 30s - loss: 1.0669 - accuracy: 0.5396 - val_loss: 1.0792 - val_accuracy: 0.5335
Epoch 18/100
120000/120000 - 31s - loss: 1.0623 - accuracy: 0.5414 - val_loss: 1.0804 - val_accuracy: 0.5347
Epoch 19/100
120000/120000 - 32s - loss: 1.0614 - accuracy: 0.5409 - val_loss: 1.0643 - val_accuracy: 0.5381
Epoch 20/100
120000/120000 - 31s - loss: 1.0595 - accuracy: 0.5404 - val_loss: 1.0489 - val_accuracy: 0.5487
Epoch 21/100
120000/120000 - 30s - loss: 1.0567 - accuracy: 0.5435 - val_loss: 1.0731 - val_accuracy: 0.5354
Epoch 22/100
120000/120000 - 32s - loss: 1.0572 - accuracy: 0.5416 - val_loss: 1.0466 - val_accuracy: 0.5499
Epoch 23/100
120000/120000 - 30s - loss: 1.0550 - accuracy: 0.5449 - val_loss: 1.0916 - val_accuracy: 0.5251
Epoch 24/100
120000/120000 - 30s - loss: 1.0557 - accuracy: 0.5429 - val_loss: 1.0515 - val_accuracy: 0.5487
Epoch 25/100
120000/120000 - 32s - loss: 1.0559 - accuracy: 0.5432 - val_loss: 1.0606 - val_accuracy: 0.5429
Epoch 26/100
120000/120000 - 32s - loss: 1.0513 - accuracy: 0.5467 - val_loss: 1.0487 - val_accuracy: 0.5479
Epoch 27/100
120000/120000 - 31s - loss: 1.0509 - accuracy: 0.5454 - val_loss: 1.0483 - val_accuracy: 0.5492
Epoch 28/100
120000/120000 - 32s - loss: 1.0492 - accuracy: 0.5475 - val_loss: 1.0538 - val_accuracy: 0.5458
Epoch 29/100
120000/120000 - 30s - loss: 1.0501 - accuracy: 0.5447 - val_loss: 1.0374 - val_accuracy: 0.5546
Epoch 30/100
120000/120000 - 31s - loss: 1.0487 - accuracy: 0.5466 - val_loss: 1.0608 - val_accuracy: 0.5358
Epoch 31/100
120000/120000 - 31s - loss: 1.0487 - accuracy: 0.5467 - val_loss: 1.0438 - val_accuracy: 0.5521
Epoch 32/100
120000/120000 - 31s - loss: 1.0491 - accuracy: 0.5469 - val_loss: 1.0477 - val_accuracy: 0.5479
Epoch 33/100
120000/120000 - 32s - loss: 1.0493 - accuracy: 0.5466 - val_loss: 1.0727 - val_accuracy: 0.5313
Epoch 34/100
120000/120000 - 31s - loss: 1.0480 - accuracy: 0.5469 - val_loss: 1.0708 - val_accuracy: 0.5347
Epoch 35/100
120000/120000 - 32s - loss: 1.0470 - accuracy: 0.5486 - val_loss: 1.0395 - val_accuracy: 0.5540
Epoch 36/100
120000/120000 - 32s - loss: 1.0482 - accuracy: 0.5486 - val_loss: 1.0515 - val_accuracy: 0.5476
Epoch 37/100
120000/120000 - 32s - loss: 1.0458 - accuracy: 0.5473 - val_loss: 1.0360 - val_accuracy: 0.5566
Epoch 38/100
120000/120000 - 31s - loss: 1.0447 - accuracy: 0.5500 - val_loss: 1.0493 - val_accuracy: 0.5510
Epoch 39/100
120000/120000 - 31s - loss: 1.0446 - accuracy: 0.5485 - val_loss: 1.0655 - val_accuracy: 0.5387
Epoch 40/100
120000/120000 - 32s - loss: 1.0454 - accuracy: 0.5495 - val_loss: 1.0328 - val_accuracy: 0.5596
Epoch 41/100
120000/120000 - 33s - loss: 1.0432 - accuracy: 0.5500 - val_loss: 1.0341 - val_accuracy: 0.5587
Epoch 42/100
120000/120000 - 32s - loss: 1.0465 - accuracy: 0.5485 - val_loss: 1.0537 - val_accuracy: 0.5501
Epoch 43/100
120000/120000 - 24s - loss: 1.0437 - accuracy: 0.5489 - val_loss: 1.0382 - val_accuracy: 0.5559
Epoch 44/100
120000/120000 - 24s - loss: 1.0440 - accuracy: 0.5492 - val_loss: 1.0485 - val_accuracy: 0.5500
Epoch 45/100
120000/120000 - 19s - loss: 1.0428 - accuracy: 0.5494 - val_loss: 1.0474 - val_accuracy: 0.5498
Epoch 46/100
120000/120000 - 19s - loss: 1.0433 - accuracy: 0.5480 - val_loss: 1.0375 - val_accuracy: 0.5564
Epoch 47/100
120000/120000 - 19s - loss: 1.0427 - accuracy: 0.5487 - val_loss: 1.0322 - val_accuracy: 0.5573
Epoch 48/100
120000/120000 - 3120s - loss: 1.0418 - accuracy: 0.5495 - val_loss: 1.0363 - val_accuracy: 0.5534
Epoch 49/100
120000/120000 - 27s - loss: 1.0430 - accuracy: 0.5490 - val_loss: 1.0737 - val_accuracy: 0.5320
Epoch 50/100
120000/120000 - 18s - loss: 1.0415 - accuracy: 0.5512 - val_loss: 1.0407 - val_accuracy: 0.5543
Epoch 51/100
120000/120000 - 3217s - loss: 1.0421 - accuracy: 0.5489 - val_loss: 1.0516 - val_accuracy: 0.5448
Epoch 52/100
120000/120000 - 21s - loss: 1.0407 - accuracy: 0.5499 - val_loss: 1.0828 - val_accuracy: 0.5307
Epoch 53/100
120000/120000 - 15s - loss: 1.0417 - accuracy: 0.5504 - val_loss: 1.0392 - val_accuracy: 0.5500
Epoch 54/100
120000/120000 - 3214s - loss: 1.0410 - accuracy: 0.5502 - val_loss: 1.0530 - val_accuracy: 0.5426
Epoch 55/100
120000/120000 - 23s - loss: 1.0405 - accuracy: 0.5490 - val_loss: 1.0488 - val_accuracy: 0.5461
Epoch 56/100
120000/120000 - 16s - loss: 1.0406 - accuracy: 0.5512 - val_loss: 1.0425 - val_accuracy: 0.5514
Epoch 57/100
120000/120000 - 16s - loss: 1.0404 - accuracy: 0.5498 - val_loss: 1.0429 - val_accuracy: 0.5488
Epoch 58/100
120000/120000 - 3218s - loss: 1.0403 - accuracy: 0.5508 - val_loss: 1.0624 - val_accuracy: 0.5410
Epoch 59/100
120000/120000 - 14s - loss: 1.0405 - accuracy: 0.5506 - val_loss: 1.0418 - val_accuracy: 0.5502
Epoch 60/100
120000/120000 - 15s - loss: 1.0390 - accuracy: 0.5506 - val_loss: 1.0780 - val_accuracy: 0.5328
Epoch 61/100
120000/120000 - 3216s - loss: 1.0393 - accuracy: 0.5506 - val_loss: 1.0304 - val_accuracy: 0.5569
Epoch 62/100
120000/120000 - 15s - loss: 1.0397 - accuracy: 0.5499 - val_loss: 1.0540 - val_accuracy: 0.5481
Epoch 63/100
120000/120000 - 14s - loss: 1.0396 - accuracy: 0.5501 - val_loss: 1.0592 - val_accuracy: 0.5393
Epoch 64/100
120000/120000 - 2592s - loss: 1.0394 - accuracy: 0.5507 - val_loss: 1.1049 - val_accuracy: 0.5231
Epoch 65/100
120000/120000 - 26s - loss: 1.0389 - accuracy: 0.5525 - val_loss: 1.0593 - val_accuracy: 0.5373
Epoch 66/100
120000/120000 - 16s - loss: 1.0393 - accuracy: 0.5499 - val_loss: 1.0577 - val_accuracy: 0.5399
Epoch 67/100
120000/120000 - 15s - loss: 1.0385 - accuracy: 0.5502 - val_loss: 1.0485 - val_accuracy: 0.5442
Epoch 68/100
120000/120000 - 15s - loss: 1.0383 - accuracy: 0.5517 - val_loss: 1.0376 - val_accuracy: 0.5550
Epoch 69/100
120000/120000 - 15s - loss: 1.0383 - accuracy: 0.5520 - val_loss: 1.0341 - val_accuracy: 0.5567
Epoch 70/100
120000/120000 - 16s - loss: 1.0385 - accuracy: 0.5516 - val_loss: 1.0329 - val_accuracy: 0.5555
Epoch 71/100
120000/120000 - 16s - loss: 1.0378 - accuracy: 0.5514 - val_loss: 1.0489 - val_accuracy: 0.5506
Epoch 72/100
120000/120000 - 17s - loss: 1.0384 - accuracy: 0.5508 - val_loss: 1.0375 - val_accuracy: 0.5530
Epoch 73/100
120000/120000 - 20s - loss: 1.0371 - accuracy: 0.5522 - val_loss: 1.0484 - val_accuracy: 0.5463
Epoch 74/100
120000/120000 - 21s - loss: 1.0373 - accuracy: 0.5520 - val_loss: 1.0405 - val_accuracy: 0.5500
Epoch 75/100
120000/120000 - 17s - loss: 1.0372 - accuracy: 0.5517 - val_loss: 1.0426 - val_accuracy: 0.5473
Epoch 76/100
120000/120000 - 19s - loss: 1.0375 - accuracy: 0.5508 - val_loss: 1.1182 - val_accuracy: 0.5108
Epoch 77/100
120000/120000 - 17s - loss: 1.0376 - accuracy: 0.5505 - val_loss: 1.0894 - val_accuracy: 0.5285
Epoch 78/100
120000/120000 - 18s - loss: 1.0374 - accuracy: 0.5522 - val_loss: 1.0562 - val_accuracy: 0.5424
Epoch 79/100
120000/120000 - 17s - loss: 1.0375 - accuracy: 0.5514 - val_loss: 1.0449 - val_accuracy: 0.5496
Epoch 80/100
120000/120000 - 17s - loss: 1.0377 - accuracy: 0.5523 - val_loss: 1.0390 - val_accuracy: 0.5545
Epoch 81/100
120000/120000 - 22s - loss: 1.0358 - accuracy: 0.5522 - val_loss: 1.0349 - val_accuracy: 0.5562
Epoch 82/100
120000/120000 - 22s - loss: 1.0377 - accuracy: 0.5518 - val_loss: 1.0285 - val_accuracy: 0.5593
Epoch 83/100
120000/120000 - 19s - loss: 1.0364 - accuracy: 0.5522 - val_loss: 1.0354 - val_accuracy: 0.5555
Epoch 84/100
120000/120000 - 17s - loss: 1.0360 - accuracy: 0.5524 - val_loss: 1.0500 - val_accuracy: 0.5426
Epoch 85/100
120000/120000 - 17s - loss: 1.0373 - accuracy: 0.5513 - val_loss: 1.0434 - val_accuracy: 0.5510
Epoch 86/100
120000/120000 - 17s - loss: 1.0371 - accuracy: 0.5520 - val_loss: 1.0324 - val_accuracy: 0.5577
Epoch 87/100
120000/120000 - 18s - loss: 1.0362 - accuracy: 0.5522 - val_loss: 1.0610 - val_accuracy: 0.5401
Epoch 88/100
120000/120000 - 22s - loss: 1.0362 - accuracy: 0.5516 - val_loss: 1.0480 - val_accuracy: 0.5483
Epoch 89/100
120000/120000 - 18s - loss: 1.0360 - accuracy: 0.5521 - val_loss: 1.0305 - val_accuracy: 0.5596
Epoch 90/100
120000/120000 - 17s - loss: 1.0362 - accuracy: 0.5516 - val_loss: 1.0329 - val_accuracy: 0.5582
Epoch 91/100
120000/120000 - 17s - loss: 1.0356 - accuracy: 0.5534 - val_loss: 1.0531 - val_accuracy: 0.5449
Epoch 92/100
120000/120000 - 17s - loss: 1.0360 - accuracy: 0.5535 - val_loss: 1.0337 - val_accuracy: 0.5562
Epoch 93/100
120000/120000 - 22s - loss: 1.0363 - accuracy: 0.5524 - val_loss: 1.0670 - val_accuracy: 0.5320
Epoch 94/100
120000/120000 - 19s - loss: 1.0356 - accuracy: 0.5532 - val_loss: 1.0470 - val_accuracy: 0.5481
Epoch 95/100
120000/120000 - 21s - loss: 1.0357 - accuracy: 0.5531 - val_loss: 1.0501 - val_accuracy: 0.5478
Epoch 96/100
120000/120000 - 19s - loss: 1.0346 - accuracy: 0.5531 - val_loss: 1.0560 - val_accuracy: 0.5434
Epoch 97/100
120000/120000 - 19s - loss: 1.0363 - accuracy: 0.5523 - val_loss: 1.0288 - val_accuracy: 0.5586
Epoch 98/100
120000/120000 - 17s - loss: 1.0358 - accuracy: 0.5528 - val_loss: 1.0555 - val_accuracy: 0.5445
Epoch 99/100
120000/120000 - 18s - loss: 1.0349 - accuracy: 0.5534 - val_loss: 1.0382 - val_accuracy: 0.5526
Epoch 100/100
120000/120000 - 17s - loss: 1.0347 - accuracy: 0.5533 - val_loss: 1.0376 - val_accuracy: 0.5526
Saved model to disk
Evaluate on test data
test loss, test acc:  [1.0376462094624836, 0.55256665]
Pertenece al grupo D         grupo verdadero es  D
Pertenece al grupo D         grupo verdadero es  D
Pertenece al grupo B         grupo verdadero es  B
Pertenece al grupo B         grupo verdadero es  B
Pertenece al grupo D         grupo verdadero es  D
Pertenece al grupo B         grupo verdadero es  A
Pertenece al grupo B         grupo verdadero es  B
Pertenece al grupo D         grupo verdadero es  D
Pertenece al grupo B         grupo verdadero es  C
Pertenece al grupo B         grupo verdadero es  A
associate probabilities 
[[0.01999431 0.06422323 0.23536046 0.68042195]
 [0.02314551 0.07254086 0.24539556 0.6589181 ]
 [0.22648497 0.458624   0.22728248 0.08760851]
 [0.08890267 0.5627799  0.30952546 0.03879199]
 [0.01180281 0.04965374 0.2358634  0.70268005]
 [0.14208171 0.30519098 0.2985386  0.2541887 ]
 [0.13572189 0.38396513 0.31810638 0.16220653]
 [0.01787339 0.06147164 0.23782614 0.68282884]
 [0.10608818 0.5129978  0.31839728 0.06251673]
 [0.42142475 0.44734076 0.10149181 0.02974259]]
